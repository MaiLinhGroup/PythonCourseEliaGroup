{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<img src=\"./image/Logo/logo_elia_group.png\" width = 200>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Joining\n",
    "<br> \n",
    "\n",
    "Sometimes, it might be nesesary to **combine** several data sets. To do so, you need to have a common feature in each data set to join/(merge) data from various sources.  \n",
    "Let's look at different methods on how your data can be joined together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td><img src='./image/inner_join.png' width = 300></td><td><img src='./image/outer_join.png' width = 300></td></tr></table>\n",
    "<table><tr><td><img src='./image/left_join.png' width = 300></td><td><img src='./image/right_join.png' width = 300></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "\n",
    "In order to understand all these methods, take a look at the examples below and try to figure out how this **data joining** works. Hint: The key column on which you are merging the dataframes is column C. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\n",
    "<center><img src=\"./image/inner_join_example.png\" width = 800/></center>\n",
    "\n",
    "</br>\n",
    "<center><img src=\"./image/outer_join_example.png\" width = 800/></center>\n",
    "\n",
    "</br>\n",
    "<center><img src=\"./image/left_join_example.png\" width = 800 /></center>\n",
    "\n",
    "</br>\n",
    "<center><img src=\"./image/right_join_example.png\" width = 800 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge - First Steps\n",
    "\n",
    "Now it's your turn!\n",
    "Let's upload two data sets from [Elia Open Data API](https://www.elia.be/en/grid-data/open-data). The first data set describes the measured and upscaled **total load on the Belgian grid** and presents data from 1st Jan 2019 **until 30th Jan 2019**, whereas the second one describes the measured and upscaled **load on the Elia grid** from 1st Jan 2019 until **only the 15th Jan 2019**. <br>\n",
    "\n",
    "1. Read in the two data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_load = pd.read_csv(\"./data/energy/total_load_2019_01.csv\", sep = \";\", parse_dates = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "elia_load = pd.read_csv(\"./data/energy/elia_load_2019_01_15.csv\", sep = \";\", parse_dates = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Take a quick look at them so you know with what your are working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Total Load Data Set: \n",
      "                    DateTime Resolution code  Total Load\n",
      "0  2019-01-31T23:45:00+01:00           PT15M    11292.30\n",
      "1  2019-01-31T23:30:00+01:00           PT15M    11382.79\n",
      "2  2019-01-31T23:15:00+01:00           PT15M    11520.47\n",
      "3  2019-01-31T23:00:00+01:00           PT15M    11633.02\n",
      "4  2019-01-31T22:45:00+01:00           PT15M    11546.67\n",
      "Shape:  (2976, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"This is the Total Load Data Set: \")\n",
    "print(total_load.head())\n",
    "print(\"Shape: \", total_load.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Elia Load Data Set:\n",
      "                    Datetime Resolution code  Elia Grid Load\n",
      "0  2019-01-15T23:45:00+01:00           PT15M         9100.73\n",
      "1  2019-01-15T23:30:00+01:00           PT15M         9479.93\n",
      "2  2019-01-15T23:15:00+01:00           PT15M         9645.24\n",
      "3  2019-01-15T23:00:00+01:00           PT15M         9691.24\n",
      "4  2019-01-15T22:45:00+01:00           PT15M         9717.09\n",
      "Shape:  (1440, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"This is the Elia Load Data Set:\")\n",
    "print(elia_load.head())\n",
    "print(\"Shape: \", elia_load.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to merge both data frames, you need to rename one of the Datetime columns, since their content is the same but their column is named differently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Resolution code</th>\n",
       "      <th>Elia Grid Load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-15T23:45:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>9100.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-15T23:30:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>9479.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-15T23:15:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>9645.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-15T23:00:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>9691.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-15T22:45:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>9717.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DateTime Resolution code  Elia Grid Load\n",
       "0  2019-01-15T23:45:00+01:00           PT15M         9100.73\n",
       "1  2019-01-15T23:30:00+01:00           PT15M         9479.93\n",
       "2  2019-01-15T23:15:00+01:00           PT15M         9645.24\n",
       "3  2019-01-15T23:00:00+01:00           PT15M         9691.24\n",
       "4  2019-01-15T22:45:00+01:00           PT15M         9717.09"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elia_load = elia_load.rename(columns={\"Datetime\": \"DateTime\"})\n",
    "elia_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Resolution code</th>\n",
       "      <th>Total Load</th>\n",
       "      <th>Elia Grid Load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-15T23:45:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>10201.90</td>\n",
       "      <td>9100.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-15T23:30:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>10501.04</td>\n",
       "      <td>9479.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-15T23:15:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>10665.05</td>\n",
       "      <td>9645.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-15T23:00:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>10698.07</td>\n",
       "      <td>9691.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-15T22:45:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>10685.16</td>\n",
       "      <td>9717.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2019-01-01T01:00:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>8728.57</td>\n",
       "      <td>7843.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2019-01-01T00:45:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>8746.80</td>\n",
       "      <td>7945.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2019-01-01T00:30:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>8964.21</td>\n",
       "      <td>8084.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2019-01-01T00:15:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>9060.07</td>\n",
       "      <td>8229.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2019-01-01T00:00:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>9121.72</td>\n",
       "      <td>8312.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       DateTime Resolution code  Total Load  Elia Grid Load\n",
       "0     2019-01-15T23:45:00+01:00           PT15M    10201.90         9100.73\n",
       "1     2019-01-15T23:30:00+01:00           PT15M    10501.04         9479.93\n",
       "2     2019-01-15T23:15:00+01:00           PT15M    10665.05         9645.24\n",
       "3     2019-01-15T23:00:00+01:00           PT15M    10698.07         9691.24\n",
       "4     2019-01-15T22:45:00+01:00           PT15M    10685.16         9717.09\n",
       "...                         ...             ...         ...             ...\n",
       "1435  2019-01-01T01:00:00+01:00           PT15M     8728.57         7843.09\n",
       "1436  2019-01-01T00:45:00+01:00           PT15M     8746.80         7945.00\n",
       "1437  2019-01-01T00:30:00+01:00           PT15M     8964.21         8084.29\n",
       "1438  2019-01-01T00:15:00+01:00           PT15M     9060.07         8229.64\n",
       "1439  2019-01-01T00:00:00+01:00           PT15M     9121.72         8312.95\n",
       "\n",
       "[1440 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = pd.merge(total_load, elia_load)\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Look at the merged dataframe - can you guess which kind ouf merge method you used? Since we did not specify any parameters within the merge function, this method is the default!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Resolution code</th>\n",
       "      <th>Total Load</th>\n",
       "      <th>Elia Grid Load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-31T23:45:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>11292.30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-31T23:30:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>11382.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-31T23:15:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>11520.47</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-31T23:00:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>11633.02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-31T22:45:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>11546.67</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>2019-01-01T01:00:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>8728.57</td>\n",
       "      <td>7843.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>2019-01-01T00:45:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>8746.80</td>\n",
       "      <td>7945.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2973</th>\n",
       "      <td>2019-01-01T00:30:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>8964.21</td>\n",
       "      <td>8084.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>2019-01-01T00:15:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>9060.07</td>\n",
       "      <td>8229.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>2019-01-01T00:00:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>9121.72</td>\n",
       "      <td>8312.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2976 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       DateTime Resolution code  Total Load  Elia Grid Load\n",
       "0     2019-01-31T23:45:00+01:00           PT15M    11292.30             NaN\n",
       "1     2019-01-31T23:30:00+01:00           PT15M    11382.79             NaN\n",
       "2     2019-01-31T23:15:00+01:00           PT15M    11520.47             NaN\n",
       "3     2019-01-31T23:00:00+01:00           PT15M    11633.02             NaN\n",
       "4     2019-01-31T22:45:00+01:00           PT15M    11546.67             NaN\n",
       "...                         ...             ...         ...             ...\n",
       "2971  2019-01-01T01:00:00+01:00           PT15M     8728.57         7843.09\n",
       "2972  2019-01-01T00:45:00+01:00           PT15M     8746.80         7945.00\n",
       "2973  2019-01-01T00:30:00+01:00           PT15M     8964.21         8084.29\n",
       "2974  2019-01-01T00:15:00+01:00           PT15M     9060.07         8229.64\n",
       "2975  2019-01-01T00:00:00+01:00           PT15M     9121.72         8312.95\n",
       "\n",
       "[2976 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_merged = pd.merge(total_load, elia_load, how = \"outer\")\n",
    "df2_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional parameters of merge\n",
    "\n",
    "Obviously, you can do way more then just \"inner\" or \"outer\" merging. There are lots of parameters with which you can specify things like merging method or add suffixes. Find out all about the different parameters in merge [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html). <br>\n",
    "Let's check out some of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(pd.merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Resolution code_total</th>\n",
       "      <th>Total Load</th>\n",
       "      <th>Resolution code_elia</th>\n",
       "      <th>Elia Grid Load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-31T23:45:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>11292.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-31T23:30:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>11382.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-31T23:15:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>11520.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-31T23:00:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>11633.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-31T22:45:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>11546.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>2019-01-01T01:00:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>8728.57</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>7843.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>2019-01-01T00:45:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>8746.80</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>7945.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2973</th>\n",
       "      <td>2019-01-01T00:30:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>8964.21</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>8084.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>2019-01-01T00:15:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>9060.07</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>8229.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>2019-01-01T00:00:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>9121.72</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>8312.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2976 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       DateTime Resolution code_total  Total Load  \\\n",
       "0     2019-01-31T23:45:00+01:00                 PT15M    11292.30   \n",
       "1     2019-01-31T23:30:00+01:00                 PT15M    11382.79   \n",
       "2     2019-01-31T23:15:00+01:00                 PT15M    11520.47   \n",
       "3     2019-01-31T23:00:00+01:00                 PT15M    11633.02   \n",
       "4     2019-01-31T22:45:00+01:00                 PT15M    11546.67   \n",
       "...                         ...                   ...         ...   \n",
       "2971  2019-01-01T01:00:00+01:00                 PT15M     8728.57   \n",
       "2972  2019-01-01T00:45:00+01:00                 PT15M     8746.80   \n",
       "2973  2019-01-01T00:30:00+01:00                 PT15M     8964.21   \n",
       "2974  2019-01-01T00:15:00+01:00                 PT15M     9060.07   \n",
       "2975  2019-01-01T00:00:00+01:00                 PT15M     9121.72   \n",
       "\n",
       "     Resolution code_elia  Elia Grid Load  \n",
       "0                     NaN             NaN  \n",
       "1                     NaN             NaN  \n",
       "2                     NaN             NaN  \n",
       "3                     NaN             NaN  \n",
       "4                     NaN             NaN  \n",
       "...                   ...             ...  \n",
       "2971                PT15M         7843.09  \n",
       "2972                PT15M         7945.00  \n",
       "2973                PT15M         8084.29  \n",
       "2974                PT15M         8229.64  \n",
       "2975                PT15M         8312.95  \n",
       "\n",
       "[2976 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_merged = total_load.merge(elia_load, on = \"DateTime\", how = \"left\", suffixes=(\"_total\", \"_elia\"))\n",
    "\n",
    "df3_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you remember how you renamed the datetime column of the `elia_load` dataframe in order to merge it afterwards? You don't need to do that. Instead, you can use the parameters **left_on** and **right_on**. To do so, let's import the data again, but store it into another variable called `elia_load_2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "elia_load_2 = pd.read_csv(\"./data/energy/elia_load_2019_01_15.csv\", sep = \";\", parse_dates = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the column names of your two dataframes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Resolution code</th>\n",
       "      <th>Elia Grid Load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-15T23:45:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>9100.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-15T23:30:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>9479.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-15T23:15:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>9645.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Datetime Resolution code  Elia Grid Load\n",
       "0  2019-01-15T23:45:00+01:00           PT15M         9100.73\n",
       "1  2019-01-15T23:30:00+01:00           PT15M         9479.93\n",
       "2  2019-01-15T23:15:00+01:00           PT15M         9645.24"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elia_load_2.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Resolution code</th>\n",
       "      <th>Total Load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-31T23:45:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>11292.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-31T23:30:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>11382.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-31T23:15:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>11520.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DateTime Resolution code  Total Load\n",
       "0  2019-01-31T23:45:00+01:00           PT15M    11292.30\n",
       "1  2019-01-31T23:30:00+01:00           PT15M    11382.79\n",
       "2  2019-01-31T23:15:00+01:00           PT15M    11520.47"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_load.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the datetime columns are basically the same, **BUT** renamed differently. To still be able to merge these to dataframes based **on** this datetime column, you can use **\"left_on\"** and **\"right_on\"**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Resolution code_total</th>\n",
       "      <th>Elia Grid Load</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Resolution code_elia</th>\n",
       "      <th>Total Load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-15T23:45:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>9100.73</td>\n",
       "      <td>2019-01-15T23:45:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>10201.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-15T23:30:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>9479.93</td>\n",
       "      <td>2019-01-15T23:30:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>10501.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-15T23:15:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>9645.24</td>\n",
       "      <td>2019-01-15T23:15:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>10665.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-15T23:00:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>9691.24</td>\n",
       "      <td>2019-01-15T23:00:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>10698.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-15T22:45:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>9717.09</td>\n",
       "      <td>2019-01-15T22:45:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>10685.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2019-01-01T01:00:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>7843.09</td>\n",
       "      <td>2019-01-01T01:00:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>8728.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2019-01-01T00:45:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>7945.00</td>\n",
       "      <td>2019-01-01T00:45:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>8746.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2019-01-01T00:30:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>8084.29</td>\n",
       "      <td>2019-01-01T00:30:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>8964.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2019-01-01T00:15:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>8229.64</td>\n",
       "      <td>2019-01-01T00:15:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>9060.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2019-01-01T00:00:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>8312.95</td>\n",
       "      <td>2019-01-01T00:00:00+01:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>9121.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Datetime Resolution code_total  Elia Grid Load  \\\n",
       "0     2019-01-15T23:45:00+01:00                 PT15M         9100.73   \n",
       "1     2019-01-15T23:30:00+01:00                 PT15M         9479.93   \n",
       "2     2019-01-15T23:15:00+01:00                 PT15M         9645.24   \n",
       "3     2019-01-15T23:00:00+01:00                 PT15M         9691.24   \n",
       "4     2019-01-15T22:45:00+01:00                 PT15M         9717.09   \n",
       "...                         ...                   ...             ...   \n",
       "1435  2019-01-01T01:00:00+01:00                 PT15M         7843.09   \n",
       "1436  2019-01-01T00:45:00+01:00                 PT15M         7945.00   \n",
       "1437  2019-01-01T00:30:00+01:00                 PT15M         8084.29   \n",
       "1438  2019-01-01T00:15:00+01:00                 PT15M         8229.64   \n",
       "1439  2019-01-01T00:00:00+01:00                 PT15M         8312.95   \n",
       "\n",
       "                       DateTime Resolution code_elia  Total Load  \n",
       "0     2019-01-15T23:45:00+01:00                PT15M    10201.90  \n",
       "1     2019-01-15T23:30:00+01:00                PT15M    10501.04  \n",
       "2     2019-01-15T23:15:00+01:00                PT15M    10665.05  \n",
       "3     2019-01-15T23:00:00+01:00                PT15M    10698.07  \n",
       "4     2019-01-15T22:45:00+01:00                PT15M    10685.16  \n",
       "...                         ...                  ...         ...  \n",
       "1435  2019-01-01T01:00:00+01:00                PT15M     8728.57  \n",
       "1436  2019-01-01T00:45:00+01:00                PT15M     8746.80  \n",
       "1437  2019-01-01T00:30:00+01:00                PT15M     8964.21  \n",
       "1438  2019-01-01T00:15:00+01:00                PT15M     9060.07  \n",
       "1439  2019-01-01T00:00:00+01:00                PT15M     9121.72  \n",
       "\n",
       "[1440 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4_merged = elia_load_2.merge(total_load, left_on = \"Datetime\", right_on = \"DateTime\", suffixes=(\"_total\", \"_elia\"))\n",
    "\n",
    "df4_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#128526; Cool, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Now it's your turn! \n",
    "\n",
    "- Check out the following two data frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_job = pd.DataFrame({'employee': ['Bob', 'Jake', 'Ahmed', 'Sue'],\n",
    "                    'group': ['Data Science', 'Data Engineering', 'Data Engineering', 'Data Analyst']})\n",
    "df2_hired = pd.DataFrame({'employee': ['Ahmed', 'Bob', 'Jake', 'Sue'],\n",
    "                    'hire_date': [2006, 2008, 2014, 2021]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- print out the first three rows of each DataFrame before merging\n",
    "- Merge the following dataframes based on their name and save it into a new dataframe called df_job_hired\n",
    "- print out the first 3 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Exercise\n",
    "\n",
    "In the DataFrame `df2_hired` somebody changed the name of the employee column. In addition, a column called `responsibility` was added. \n",
    "\n",
    "- See if both `responsibility` columns represent the same values and can be merged into one column.\n",
    "\n",
    "- Merge the two DataFrames, save them in a new variable called `df_job_hired_2`.\n",
    "- Add suffixes (\"_job\", \"_hired\") so you can still distinguish the columns after merging. \n",
    "- In the end, print out the DataFrame.\n",
    "\n",
    "&#128161; <ins>Hint</ins>: Use the parameters left_on, right_on of the .merge() function. And don't forget, you can always check the documentation if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_job = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                       'group': ['Data Science', 'Data Engineering', 'Data Engineering', 'Data Analyst'],\n",
    "                    'responsibility': [\"Energy Forecast\", \"Data pipelines\", \"Data pipelines\", \"Interpreting Results\"]})\n",
    "\n",
    "df2_hired = pd.DataFrame({'employee_names': ['Lisa', 'Bob', 'Jake', 'Sue'],\n",
    "                         'hire_date': [2004, 2008, 2012, 2014],\n",
    "                         'responsibility': [\"yes\", \"no\", \"no\", \"yes\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating two dataframes\n",
    "<br>\n",
    "\n",
    "You can also stitch two, three or more dataframes together with `.concat()`. Let's get right to it! <br>\n",
    "For the following example, you need to import three new data sets. They all describe the physical energy flows on the interconnections between the Belgian bidding zone and the neighbouring bidding zones. A positive figure means export from Belgium, while negative figure means import into Belgium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in files\n",
    "df_morning = pd.read_csv(\"data/energy/PhysicalFlow_0-8.csv\", index_col=0)\n",
    "df_noon = pd.read_csv(\"data/energy/PhysicalFlow_8-16.csv\", index_col=0)\n",
    "df_evening = pd.read_csv(\"data/energy/PhysicalFlow_16-24.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Resolution code</th>\n",
       "      <th>Control area</th>\n",
       "      <th>Physical Flow Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2021-12-01 07:45:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>Germany</td>\n",
       "      <td>-537.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2021-12-01 07:30:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>Germany</td>\n",
       "      <td>-538.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2021-12-01 07:15:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>Germany</td>\n",
       "      <td>-522.304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Datetime Resolution code Control area  Physical Flow Value\n",
       "64  2021-12-01 07:45:00           PT15M      Germany             -537.172\n",
       "65  2021-12-01 07:30:00           PT15M      Germany             -538.348\n",
       "66  2021-12-01 07:15:00           PT15M      Germany             -522.304"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_morning.head(n=3) #includes data from 0-8 am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Resolution code</th>\n",
       "      <th>Control area</th>\n",
       "      <th>Physical Flow Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2021-12-01 15:45:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>Germany</td>\n",
       "      <td>-519.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2021-12-01 15:30:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>Germany</td>\n",
       "      <td>-501.404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2021-12-01 15:15:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>Germany</td>\n",
       "      <td>-499.612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Datetime Resolution code Control area  Physical Flow Value\n",
       "32  2021-12-01 15:45:00           PT15M      Germany             -519.664\n",
       "33  2021-12-01 15:30:00           PT15M      Germany             -501.404\n",
       "34  2021-12-01 15:15:00           PT15M      Germany             -499.612"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_noon.head(n=3) #includes data from 8-16 am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Resolution code</th>\n",
       "      <th>Control area</th>\n",
       "      <th>Physical Flow Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-01 23:45:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>Germany</td>\n",
       "      <td>-1001.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-01 23:30:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>Germany</td>\n",
       "      <td>-1002.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-01 23:15:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>Germany</td>\n",
       "      <td>-1001.796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Datetime Resolution code Control area  Physical Flow Value\n",
       "0  2021-12-01 23:45:00           PT15M      Germany            -1001.788\n",
       "1  2021-12-01 23:30:00           PT15M      Germany            -1002.104\n",
       "2  2021-12-01 23:15:00           PT15M      Germany            -1001.796"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evening.head(n=3) #includes data from 16-24 am"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of your new data sets is the follwing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Morning Dataframe: (32, 4)\n",
      "Shape of Noon Dataframe: (32, 4)\n",
      "Shape of Evening Dataframe: (32, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Morning Dataframe: \" + str(df_morning.shape))\n",
    "print(\"Shape of Noon Dataframe: \" + str(df_noon.shape))\n",
    "print(\"Shape of Evening Dataframe: \" + str(df_evening.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#128077; nice! ... maybe you have already discovered that the data sets are from the same day - but different times of day. So let's put them together with the new function .concat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df_concat: (96, 4)\n"
     ]
    }
   ],
   "source": [
    "df_concat = pd.concat([df_morning, df_noon, df_evening ]).sort_values(\"Datetime\").reset_index(drop=True)\n",
    "print(\"Shape of df_concat: \" + str(df_concat.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional parameters in concat()\n",
    "<br> \n",
    "\n",
    "As always, there are many more things you can do with concat(). [See for yourself](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html) or use the help function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(pd.concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's redo the last example and verify integrity, which means, checking for duplicates in the three dataframes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df_morning, df_noon, df_evening], verify_integrity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might wonder, why \"nothing has happend\". Well, let's create a data frame WITH duplicates. <br>\n",
    "The following dataset also includes morning daytimes from 0 pm until 9 am but overlaps with the `df_noon` data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Resolution code</th>\n",
       "      <th>Control area</th>\n",
       "      <th>Physical Flow Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2021-12-01 09:00:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>Germany</td>\n",
       "      <td>-511.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2021-12-01 08:45:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>Germany</td>\n",
       "      <td>-614.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2021-12-01 08:30:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>Germany</td>\n",
       "      <td>-624.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2021-12-01 08:15:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>Germany</td>\n",
       "      <td>-624.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2021-12-01 08:00:00</td>\n",
       "      <td>PT15M</td>\n",
       "      <td>Germany</td>\n",
       "      <td>-596.836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Datetime Resolution code Control area  Physical Flow Value\n",
       "59  2021-12-01 09:00:00           PT15M      Germany             -511.740\n",
       "60  2021-12-01 08:45:00           PT15M      Germany             -614.928\n",
       "61  2021-12-01 08:30:00           PT15M      Germany             -624.604\n",
       "62  2021-12-01 08:15:00           PT15M      Germany             -624.016\n",
       "63  2021-12-01 08:00:00           PT15M      Germany             -596.836"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_duplicates = pd.read_csv(\"data/energy/PhysicalFlow_0-9.csv\", index_col = 0)\n",
    "\n",
    "df_duplicates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you now concatenate them and check for duplicates, an error message will appear: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Indexes have overlapping values: Int64Index([59, 60, 61, 62, 63], dtype='int64')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-38d9c233fac0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_concat_dupl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_duplicates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_noon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_evening\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \"\"\"\n\u001b[0;32m--> 274\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_new_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m_get_new_axes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_new_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_result_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         return [\n\u001b[0m\u001b[1;32m    520\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concat_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbm_axis\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_comb_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_result_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         return [\n\u001b[0;32m--> 520\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concat_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbm_axis\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_comb_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         ]\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m_get_concat_axis\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    578\u001b[0m             )\n\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m_maybe_check_integrity\u001b[0;34m(self, concat_index)\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconcat_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m                 \u001b[0moverlap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconcat_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Indexes have overlapping values: {overlap}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Indexes have overlapping values: Int64Index([59, 60, 61, 62, 63], dtype='int64')"
     ]
    }
   ],
   "source": [
    "df_concat_dupl = pd.concat([df_duplicates, df_noon, df_evening], verify_integrity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See, you will get an error message if there are duplicates within your dataframes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "In the following, two dataframes (`dp1_df`, and `dp2_df`) are given. They both describe a number of employees working on a data related project together. They share the same column names. \n",
    "\n",
    "- Concatenate the dataframes and save them in a new dataframe called `data_project_df`.\n",
    "- When you concatenated the dataframes, have a look at the index - it is not continuous. \n",
    "- Add the parameter \"ignore_index = True\" to create a continuous index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp1_df = pd.DataFrame([{'Name': 'Kelly', 'Role': 'Director of HR', 'Location': 'State Street'},\n",
    "                         {'Name': 'Sally', 'Role': 'Data Scientist', 'Location': 'Washington Avenue'},\n",
    "                         {'Name': 'James', 'Role': 'Data Engineer', 'Location': 'Washington Avenue'}])\n",
    "dp2_df = pd.DataFrame([{'Name': 'James', 'Role': 'Analyst', 'Location': '1024 Billiard Avenue'},\n",
    "                           {'Name': 'Mike', 'Role': 'Regulations', 'Location': 'Fraternity House #22'},\n",
    "                           {'Name': 'Sally', 'Role': 'MlOps', 'Location': '512 Wilson Crescent'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
