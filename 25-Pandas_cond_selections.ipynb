{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<img src=\"./image/Logo/logo_elia_group.png\" width = 200>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Selections: Filtering\n",
    "<br>\n",
    "\n",
    "One of the most beloved and useful function in excel is the filter function - and of course, you can do the same in Python. You can use conditional selections to select specific rows and narrow your analysis down. And to make things easier, you can save selections you plan to use often as their own variables. Let's get right to it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"./image/conditional_selections.png\" width = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's have a look at the dataset \"physical flow\" again: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_flow = pd.read_csv(\"./data/energy/physical_flow_2021_1_01.csv\", sep = \";\", parse_dates = True, index_col = 0)\n",
    "energy_flow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the data set describes different physical flow values from different countries (the neighbouring bidding zones of Belgium), measured at similar datetimes.\n",
    "Let's check which countries are represented here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_flow[\"Control area\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you want to take a closer look at France and Luxembourg. To do so, you need to select the column of interest and \"filter\" your area of choice with a conditional statement which returns either True or False. This is then used to filter your data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "france = energy_flow[energy_flow[\"Control area\"] == \"France\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "luxembourg = energy_flow[energy_flow[\"Control area\"] == \"Luxembourg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "france.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "luxembourg.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise\n",
    "\n",
    "1. Look at the dataframe `energy_flow` above and select the control area \"Germany\". \n",
    "2. Save your selection into a variable called `germany`.\n",
    "3. Look at the first three rows to see if it worked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data set includes hourly data from one day, you could calculate the mean physical flow of that day per selected country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Physical Flow of France in MW: ', round(france['Physical Flow Value'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Physical Flow of Luxembourg in MW: ', round(luxembourg['Physical Flow Value'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a positive figure means export from Belgium, you can now use these to calculate more targeted metrics: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('On that day, Belgium exports {} MW on average more to France compared to Luxembourg.'\\\n",
    "      .format(round(france['Physical Flow Value'].mean() - luxembourg['Physical Flow Value'].mean(),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Conditionals: Using Masks \n",
    "<br>\n",
    "\n",
    "Sure, it is nice to filter just one thing. But what if you want **to filter on > 1 criteria**? Then it can be easier to use a mask. No, not a face mask. Rather a boolean mask. <br>\n",
    "\n",
    "Imagine you would like to not just select France OR Luxembourg, but both countries as well as Germany. With a mask, you specify these multiple conditions. Your mask evaluates the different conditions and returns either TRUE/FALSE. In a second step this mask is used as a filter as you have already learned in Filtering.\n",
    "The pipe operator `|` is used as on OR whereas the `&` is used as an AND. But enough talking, let's try it out! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a variable that stores all the conditions you would like to choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_mask = (energy_flow[\"Control area\"] == \"France\") | (energy_flow[\"Control area\"] == \"Luxembourg\") | (energy_flow[\"Control area\"] == \"Germany\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Look at your mask. It returns whether your conditions have been met for each row or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now you can directly access your mask, using: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_countries = energy_flow[countries_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_countries[\"Control area\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#128526; nice, well done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create another mask just for fun. Now we want to have all the data related to a physical flow is higher 1000 MW and find out whether it is import or export. For that, let's have a look at the original dataframe again: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_flow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define that in this case, a high physical flow means < - 1000 MW and > 1000 MW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_flow_mask = (energy_flow[\"Physical Flow Value\"] < -1000) | (energy_flow[\"Physical Flow Value\"] > 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_flow_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_flow = energy_flow[high_flow_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_flow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby\n",
    "<br> \n",
    "\n",
    "One of the most flexible ways to group your data and aggregate in pandas is with `.groupby()`. So what does this actually mean? Let's have a look at the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_flow.groupby(\"Control area\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the example above, `groupby()` groups your data by the column(s) that you hand over to the function. In this case \"Control area\". In addition, `groupby()` **only works with an aggregator** such as sum() or mean(). This means, you have to tell the function what to do with each group. In this case, calculate the mean using `mean()`. Also notice, that the **column you grouped on/by becomes your new index**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "Do you know why only the column \"Physical Flow Value\" is displayed in our example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do many more cool things. If you want to change the order in which the aggregated values are displayed, you can just chain the command `.sort_values` to your groupby statement. In general, you can use `.sort_values` for sorting any  column of a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_flow.groupby(\"Control area\").mean().sort_values(by=[\"Physical Flow Value\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our next example, let's have a look at a bigger and more complex data set. To do so, you first have to import the csv: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_high_voltage = pd.read_csv(\"./data/energy/physical_flow_high_voltage_2022_may_30.csv\", sep = \";\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_high_voltage.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set above describes the physical flow on the Belgian 380-kV lines (high-voltage) and on the interconnections with the neighboring countries. The \"Loading\" indicates how heavily the line is loaded relative to the maximum possible line loading. For the purpose of this training, you look at the data from only one day - the 30th of May 2022. The \"Physical Flow\" is given in MW whereas the \"Loading\" is given in %. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use what we have learned so far: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_high_voltage.groupby(\"Asset name\").mean().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip:** Sometimes, if you want to aggregate different columns in different ways and to make your code cleaner, it is best to move the aggregations out and store them as a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs = {\n",
    "    'Physical Flow': 'mean',\n",
    "    'Loading': 'max'\n",
    "}\n",
    "\n",
    "pf_high_voltage.groupby('Asset name').agg(aggs).sort_values(by=['Physical Flow','Loading']).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to aggregate a certain column in several different ways, you can store the column and the different aggregators as key-value pairs in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs2 = {\n",
    "    'Loading': ['min', 'mean', 'max', 'std']\n",
    "}\n",
    "\n",
    "loading_stats = pf_high_voltage.groupby('Asset name').agg(aggs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this multi-aggregation creates a **multi-index**. Multi-indexes can be difficult to work with. But no worries, there is an easy way to deal with it. For instance, you can **drop the top level**. In this case \"Loading\": "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_stats.columns = loading_stats.columns.droplevel(level = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be necessary to rename the new \"columns\", so you keep in mind that they are all stats of \"loading\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_stats.columns = [\"loading_min\", \"loading_mean\", \"loading_max\", \"loading_std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, you can sort by any of the columns. Here, by average loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_stats.sort_values(by='loading_mean', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the max and min values with Index Max and Min\n",
    "<br>\n",
    "\n",
    "The last cool thing that is definitely worth learning in the beginning is `idxmin` and `idxmax`. In addition to `.max()` and `.min()`, which returns the maximum or minimum values, you can use `.idxmax()` and `.idxmin()` to return the *index* pertaining to the maximum and minimum values. <br>\n",
    "\n",
    "For example, let's use `.idxmax()` to find the \"Asset name\" with the highest standard deviation in its loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_stats[\"loading_std\"].idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Recap, Tips & Takeaways &#128161;\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "**Let's see what might be cool to keep in mind:**\n",
    "\n",
    "- there are two ways to combine dataframes: `pd.merge()` and `pd.concat()`\n",
    "- you can get quick stats with `df_name.describe()`\n",
    "- `df_name[\"column_name\"].unique()` lists all the unique values within a column \n",
    "- filters in Python are a boolean conditional selection: `df_name[df_name[\"column_name\"] == \"target_value\"]`\n",
    "- multiple filters can be linked together with `|` and  `&` statement\n",
    "- you can define aggregators for several columns with a dictionary: <br>\n",
    "    \n",
    "    aggs = {\n",
    "        'column_1': 'mean',\n",
    "        'column_2': 'max'\n",
    "    }\n",
    "        \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
